{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d238dda7",
   "metadata": {},
   "source": [
    "## Sympy - partial derivative and batch gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f3938",
   "metadata": {},
   "source": [
    "$$ f(x,y) = \\frac {1} {{3^{-x^2 - y^2}}+1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e53b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x,y):\n",
    "    r = 3**(-x**2 - y**2)\n",
    "    return 1/(r+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5d6e5c",
   "metadata": {},
   "source": [
    "### Partial Derivative & Symbolic Computation with Sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1db2e638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0368089716197505\n"
     ]
    }
   ],
   "source": [
    "import sympy\n",
    "from sympy import symbols,diff\n",
    "\n",
    "a,b = symbols(\"x,y\")\n",
    "\n",
    "diff(f(a,b),b)     #derivative respect to y, so df/ dy\n",
    "\n",
    "f(a,b).evalf(subs={a:1.9,b:5})   #finding function value at (1.9,5) point\n",
    "\n",
    "\n",
    "#Find slope at point (1.9,5) with respect to x (so eavluate df/dx at this point)\n",
    "diff(f(a,b),a).evalf(subs={a:1.9,b:5})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0535b1",
   "metadata": {},
   "source": [
    "### Batch gradient Descent with Sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df01c8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " minima at x is 0.000793898510134722 ,minima at y is 0.000441054727852623\n",
      "Cost funtion value at minima 0.500000226534985\n",
      "Value of gradients at minima [0.000461440542096373 0.000256355856720208]\n"
     ]
    }
   ],
   "source": [
    "#setup, initial x = 1.8, y = 1.0 ... if more than 1, use ndarray\n",
    "import numpy as np\n",
    "step_multiplier = 0.1\n",
    "max_iter = 200\n",
    "params = np.array([1.8,1.0])\n",
    "for i in range(max_iter):\n",
    "    gradient_x = diff(f(a,b),a).evalf(subs={a:params[0],b:params[1]})\n",
    "    gradient_y = diff(f(a,b),b).evalf(subs={a:params[0],b:params[1]})\n",
    "    gradients = np.array([gradient_x,gradient_y])\n",
    "    params = params - (step_multiplier*gradients)\n",
    "\n",
    "\n",
    "print(f\" minima at x is {params[0]} ,minima at y is {params[1]}\")\n",
    "print(f\"Cost funtion value at minima {f(params[0],params[1])}\")\n",
    "print(f\"Value of gradients at minima {gradients}\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde96fc7",
   "metadata": {},
   "source": [
    "### Batch Gradient Descent Without Sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45c677c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the partial derivative functions \n",
    "def fpx(x,y):\n",
    "    r = 3**(-x**2 - y**2)\n",
    "    return 2*x*np.log(3)*r / (r + 1)**2\n",
    "\n",
    "def fpy(x,y):\n",
    "    r = 3**(-x**2 - y**2)\n",
    "    return 2*y*np.log(3)*r / (r + 1)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0553f7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " minima at x is 0.0007938985101347202 ,minima at y is 0.0004410547278526219\n",
      "Cost funtion value at minima 0.5000002265349848\n",
      "Value of gradients at minima [0.00046144 0.00025636]\n"
     ]
    }
   ],
   "source": [
    "step_multiplier = 0.1\n",
    "max_iter = 200\n",
    "params = np.array([1.8,1.0])\n",
    "for _ in range(max_iter):\n",
    "    gradient_x = fpx(params[0],params[1])\n",
    "    gradient_y = fpy(params[0],params[1])\n",
    "    gradients = np.array([gradient_x,gradient_y])\n",
    "    params = params - (step_multiplier*gradients)\n",
    "\n",
    "print(f\" minima at x is {params[0]} ,minima at y is {params[1]}\")\n",
    "print(f\"Cost funtion value at minima {f(params[0],params[1])}\")\n",
    "print(f\"Value of gradients at minima {gradients}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b8643c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
